{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Recommendations').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023070\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"ratings_beauty.csv\",header=True)#.limit(600000)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. String index features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+----------+------------+---------------+\n",
      "|        UserId| ProductId|Rating| Timestamp|UserId_index|ProductId_index|\n",
      "+--------------+----------+------+----------+------------+---------------+\n",
      "|A39HTATAQ9V7YF|0205616461|   5.0|1369699200|    310478.0|        34788.0|\n",
      "|A3JM6GV9MNOF9X|0558925278|   3.0|1355443200|    339571.0|        26412.0|\n",
      "|A1Z513UWSAAO0F|0558925278|   5.0|1404691200|    177109.0|        26412.0|\n",
      "|A1WMRR494NWEWV|0733001998|   4.0|1382572800|    169869.0|        34789.0|\n",
      "|A3IAAVS479H7M7|0737104473|   1.0|1274227200|      9458.0|        34790.0|\n",
      "| AKJHHD5VEH7VG|0762451459|   5.0|1404518400|       291.0|        34791.0|\n",
      "|A1BG8QW55XHN6U|1304139212|   5.0|1371945600|       186.0|        34792.0|\n",
      "|A22VW0P4VZHDE3|1304139220|   5.0|1373068800|       742.0|        34793.0|\n",
      "|A3V3RE4132GKRO|130414089X|   5.0|1401840000|    372382.0|        34794.0|\n",
      "|A327B0I7CYTEJC|130414643X|   4.0|1389052800|    289307.0|        21564.0|\n",
      "|A1BG8QW55XHN6U|130414643X|   5.0|1372032000|       186.0|        21564.0|\n",
      "| AIFAAVTUYHEHB|130414643X|   4.0|1378252800|    417263.0|        21564.0|\n",
      "| AVOGV98AYOFG2|1304146537|   5.0|1372118400|     73856.0|        34795.0|\n",
      "|A22VW0P4VZHDE3|130414674X|   5.0|1371686400|       742.0|        34796.0|\n",
      "| AVOGV98AYOFG2|1304168522|   5.0|1372118400|     73856.0|        26413.0|\n",
      "| A6R426V4J7AOM|1304168522|   5.0|1373414400|      2224.0|        26413.0|\n",
      "|A22VW0P4VZHDE3|1304174778|   5.0|1372896000|       742.0|        26414.0|\n",
      "| AKGB62WGF35J8|1304174778|   5.0|1372896000|     69544.0|        26414.0|\n",
      "|A22VW0P4VZHDE3|1304174867|   5.0|1373068800|       742.0|        26415.0|\n",
      "|A1BG8QW55XHN6U|1304174867|   5.0|1372291200|       186.0|        26415.0|\n",
      "+--------------+----------+------+----------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in ['UserId', 'ProductId'] ]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(df).transform(df)\n",
    "\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- ProductId: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      " |-- UserId_index: double (nullable = false)\n",
      " |-- ProductId_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = ['UserId_index', 'ProductId_index', 'Rating']\n",
    "df_r = df_r.select(*(fn.col(c).cast(\"float\").alias(c) for c in model_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Out An ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+------+----------+\n",
      "|UserId_index|ProductId_index|Rating|prediction|\n",
      "+------------+---------------+------+----------+\n",
      "|      4663.0|          148.0|   2.0| 2.5258408|\n",
      "|     74206.0|          148.0|   5.0| 2.5545416|\n",
      "|     23226.0|          148.0|   4.0|  1.102417|\n",
      "|      9432.0|          148.0|   5.0| 1.9763458|\n",
      "|     31223.0|          148.0|   5.0| 3.7067816|\n",
      "|     10483.0|          148.0|   2.0| 2.8975804|\n",
      "|      4497.0|          148.0|   4.0|  1.089476|\n",
      "|     13943.0|          148.0|   4.0| 2.7961543|\n",
      "|     42925.0|          148.0|   5.0| 2.0089037|\n",
      "|       113.0|          148.0|   4.0| 3.4126592|\n",
      "|     37610.0|          148.0|   5.0| 1.8207655|\n",
      "|     18127.0|          148.0|   3.0| 2.9809241|\n",
      "|     52810.0|          148.0|   4.0| 1.6117176|\n",
      "|      5107.0|          148.0|   5.0| 3.5777962|\n",
      "|     14333.0|          463.0|   5.0|   3.52846|\n",
      "|      5572.0|          463.0|   5.0| 2.0656528|\n",
      "|     73891.0|          463.0|   5.0| 3.4963653|\n",
      "|     14568.0|          463.0|   4.0| 3.3840444|\n",
      "|     16860.0|          463.0|   4.0| 2.3005607|\n",
      "|      1609.0|          463.0|   5.0|  2.910802|\n",
      "+------------+---------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the ratings dataframe into training and test data\n",
    "(train, test) = df_r.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Set the ALS hyperparameters\n",
    "als = ALS(\n",
    "    userCol=\"UserId_index\", \n",
    "    itemCol=\"ProductId_index\", \n",
    "    ratingCol=\"Rating\", \n",
    "    rank =10, \n",
    "    maxIter =10, \n",
    "    regParam =.1,\n",
    "    coldStartStrategy=\"drop\", \n",
    "    nonnegative =True, \n",
    "    implicitPrefs = False\n",
    ")\n",
    "\n",
    "# Fit the model to the training_data\n",
    "als_model = als.fit(train)\n",
    "\n",
    "# Generate predictions on the test_data\n",
    "test_predictions = als_model.transform(test)\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RMSE Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse\n",
      "UserId_index\n",
      "ProductId_index\n",
      "32703.39096689963\n"
     ]
    }
   ],
   "source": [
    "# Import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Complete the evaluator code\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"UserId_index\", predictionCol=\"ProductId_index\")\n",
    "\n",
    "# Extract the 3 parameters\n",
    "print(evaluator.getMetricName())\n",
    "print(evaluator.getLabelCol())\n",
    "print(evaluator.getPredictionCol())\n",
    "\n",
    "\n",
    "# Evaluate the \"test_predictions\" dataframe\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# Print the RMSE\n",
    "print (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35775"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
