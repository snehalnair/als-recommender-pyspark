{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, explode\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext\n",
    "# sc.setCheckpointDir('checkpoint')\n",
    "spark = SparkSession.builder.appName('Recommendations').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.csv(\"movies.csv\",header=True)\n",
    "ratings = spark.read.csv(\"ratings.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.\\\n",
    "    withColumn('userId', col('userId').cast('integer')).\\\n",
    "    withColumn('movieId', col('movieId').cast('integer')).\\\n",
    "    withColumn('rating', col('rating').cast('float')).\\\n",
    "    drop('timestamp')\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.30% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   414| 2698|\n",
      "|   599| 2478|\n",
      "|   474| 2108|\n",
      "|   448| 1864|\n",
      "|   274| 1346|\n",
      "|   610| 1302|\n",
      "|    68| 1260|\n",
      "|   380| 1218|\n",
      "|   606| 1115|\n",
      "|   288| 1055|\n",
      "|   249| 1046|\n",
      "|   387| 1027|\n",
      "|   182|  977|\n",
      "|   307|  975|\n",
      "|   603|  943|\n",
      "|   298|  939|\n",
      "|   177|  904|\n",
      "|   318|  879|\n",
      "|   232|  862|\n",
      "|   480|  836|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by userId, count ratings\n",
    "userId_ratings = ratings.groupBy(\"userId\").count().orderBy('count', ascending=False)\n",
    "userId_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|    356|  329|\n",
      "|    318|  317|\n",
      "|    296|  307|\n",
      "|    593|  279|\n",
      "|   2571|  278|\n",
      "|    260|  251|\n",
      "|    480|  238|\n",
      "|    110|  237|\n",
      "|    589|  224|\n",
      "|    527|  220|\n",
      "|   2959|  218|\n",
      "|      1|  215|\n",
      "|   1196|  211|\n",
      "|     50|  204|\n",
      "|   2858|  204|\n",
      "|     47|  203|\n",
      "|    780|  202|\n",
      "|    150|  201|\n",
      "|   1198|  200|\n",
      "|   4993|  198|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by userId, count ratings\n",
    "movieId_ratings = ratings.groupBy(\"movieId\").count().orderBy('count', ascending=False)\n",
    "movieId_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Out An ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False, coldStartStrategy=\"drop\")\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tell Spark how to tune your ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  16\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite items\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "            .build()\n",
    "            #             .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n",
    "\n",
    "           \n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_c58e7416bfbb\n"
     ]
    }
   ],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model and Best Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALSModel'>\n",
      "**Best Model**\n",
      "  Rank: 50\n",
      "  MaxIter: 10\n",
      "  RegParam: 0.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print best_model\n",
    "print(type(best_model))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# # Print \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8682188942822926\n"
     ]
    }
   ],
   "source": [
    "# View the predictions\n",
    "test_predictions = best_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   597|    471|   2.0| 4.1357207|\n",
      "|   436|    471|   3.0| 3.6097066|\n",
      "|   218|    471|   4.0| 2.9232428|\n",
      "|   387|    471|   3.0| 3.0708382|\n",
      "|   217|    471|   2.0| 2.7097173|\n",
      "|   287|    471|   4.5| 2.9761252|\n",
      "|    32|    471|   3.0| 3.7025106|\n",
      "|   260|    471|   4.5| 3.5645263|\n",
      "|   104|    471|   4.5| 3.5195568|\n",
      "|   111|   1088|   3.0|  3.305781|\n",
      "|   177|   1088|   3.5| 3.5467803|\n",
      "|    41|   1088|   1.5|  2.449918|\n",
      "|   387|   1088|   1.5| 2.6048868|\n",
      "|   594|   1088|   4.5|  4.339765|\n",
      "|   307|   1088|   3.0| 2.6175585|\n",
      "|   509|   1088|   3.0| 3.1423986|\n",
      "|   104|   1088|   3.0| 3.6711533|\n",
      "|   268|   1238|   5.0| 3.7693748|\n",
      "|   462|   1238|   3.5|  3.369685|\n",
      "|   307|   1342|   2.0|  2.299802|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[3379, 4.834906]...|\n",
      "|   463|[[3379, 5.058715]...|\n",
      "|   496|[[3379, 4.5754867...|\n",
      "|   148|[[33649, 4.460032...|\n",
      "|   540|[[3379, 5.3912764...|\n",
      "|   392|[[3379, 4.696207]...|\n",
      "|   243|[[67618, 5.629416...|\n",
      "|    31|[[3379, 4.981336]...|\n",
      "|   516|[[4429, 4.8097], ...|\n",
      "|   580|[[3379, 4.8408875...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate n Recommendations for all users\n",
    "nrecommendations = best_model.recommendForAllUsers(10)\n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|   471|   3379| 4.834906|\n",
      "|   471|   8477| 4.575323|\n",
      "|   471|   7096|4.5383263|\n",
      "|   471|  33649|4.5357804|\n",
      "|   471|  86781|4.5016623|\n",
      "|   471|   7767|4.4983916|\n",
      "|   471| 171495| 4.490844|\n",
      "|   471| 100714| 4.419473|\n",
      "|   471|  78836|4.4031296|\n",
      "|   471|  32582|4.3969116|\n",
      "+------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecommendations = nrecommendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the recommendations makeÂ sense?\n",
    "Lets merge movie name and genres to teh recommendation matrix for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|   rating|               title|              genres|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "|  67618|   100|5.1405735|Strictly Sexual (...|Comedy|Drama|Romance|\n",
      "|   3379|   100| 5.006642| On the Beach (1959)|               Drama|\n",
      "|  33649|   100|5.0065255|  Saving Face (2004)|Comedy|Drama|Romance|\n",
      "|  42730|   100|4.9775596|   Glory Road (2006)|               Drama|\n",
      "|  74282|   100| 4.915519|Anne of Green Gab...|Children|Drama|Ro...|\n",
      "|  26073|   100| 4.874221|Human Condition I...|           Drama|War|\n",
      "| 184245|   100| 4.874221|De platte jungle ...|         Documentary|\n",
      "|  84273|   100| 4.874221|Zeitgeist: Moving...|         Documentary|\n",
      "|   7071|   100| 4.874221|Woman Under the I...|               Drama|\n",
      "| 117531|   100| 4.874221|    Watermark (2014)|         Documentary|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecommendations.join(movies, on='movieId').filter('userId = 100').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+--------------------+--------------------+\n",
      "|movieId|userId|rating|               title|              genres|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|   1101|   100|   5.0|      Top Gun (1986)|      Action|Romance|\n",
      "|   1958|   100|   5.0|Terms of Endearme...|        Comedy|Drama|\n",
      "|   2423|   100|   5.0|Christmas Vacatio...|              Comedy|\n",
      "|   4041|   100|   5.0|Officer and a Gen...|       Drama|Romance|\n",
      "|   5620|   100|   5.0|Sweet Home Alabam...|      Comedy|Romance|\n",
      "|    368|   100|   4.5|     Maverick (1994)|Adventure|Comedy|...|\n",
      "|    934|   100|   4.5|Father of the Bri...|              Comedy|\n",
      "|    539|   100|   4.5|Sleepless in Seat...|Comedy|Drama|Romance|\n",
      "|     16|   100|   4.5|       Casino (1995)|         Crime|Drama|\n",
      "|    553|   100|   4.5|    Tombstone (1993)|Action|Drama|Western|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.join(movies, on='movieId').filter('userId = 100').sort('rating', ascending=False).limit(10).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
